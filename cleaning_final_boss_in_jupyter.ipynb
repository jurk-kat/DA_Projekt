{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_of_lists(data):\n",
    "    max_distance = 0\n",
    "    current_distance = 0\n",
    "\n",
    "    for sublist in data:\n",
    "        if sublist[0] == \"*\":\n",
    "            max_distance = max(max_distance, current_distance)\n",
    "            current_distance = 0\n",
    "        else:\n",
    "            current_distance += 1\n",
    "    max_distance = max(max_distance, current_distance)\n",
    "\n",
    "    lists = [[] for _ in range(max_distance + 1)]\n",
    "\n",
    "    list_index = 0\n",
    "\n",
    "    first_asterisk = True\n",
    "\n",
    "    for sublist in data:\n",
    "\n",
    "        if sublist[0] == \"*\":\n",
    "            if not first_asterisk:\n",
    "\n",
    "                while list_index < len(lists):\n",
    "                    if lists[0]:\n",
    "                        empty_string_list = [\"\" for _ in lists[0][0]]\n",
    "                    else:\n",
    "                        empty_string_list = []\n",
    "                    lists[list_index].append(empty_string_list)\n",
    "                    list_index += 1\n",
    "\n",
    "            list_index = 0\n",
    "            first_asterisk = False\n",
    "\n",
    "        lists[list_index].append(sublist)\n",
    "\n",
    "        list_index += 1\n",
    "\n",
    "    while list_index < len(lists):\n",
    "        if lists[0]:\n",
    "            empty_string_list = [\"\" for _ in lists[0][0]]\n",
    "        else:\n",
    "            empty_string_list = []\n",
    "        lists[list_index].append(empty_string_list)\n",
    "        list_index += 1\n",
    "\n",
    "    return lists\n",
    "\n",
    "\n",
    "def corrections_in_rows(df, updates):\n",
    "    for row, collumn, value in updates:\n",
    "        df.loc[row, collumn] = value\n",
    "\n",
    "\n",
    "def corrections_in_rows_soft(df, updates):\n",
    "    for row, collumn, value in updates:\n",
    "        if pd.isna(df.loc[row, collumn]):\n",
    "            df.loc[row, collumn] = value\n",
    "\n",
    "\n",
    "def clean_time_columns(dataframe, columns):\n",
    "    for column in columns:\n",
    "        dataframe[column] = dataframe[column].str.strip(\n",
    "        ).str.strip(\":\").str.strip(\"?\")\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def reformat_time_columns(dataframe, columns):\n",
    "    for column in columns:\n",
    "        prvni_pulka = dataframe[column].str.slice(0, 2)\n",
    "        druha_pulka = dataframe[column].str.slice(2, 5)\n",
    "        dataframe[column] = prvni_pulka + \":\" + druha_pulka\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def expand_rows(row):\n",
    "    hours = pd.date_range(row[\"ETA date\"], row[\"ETD date\"], freq=\"h\")\n",
    "    return pd.DataFrame({\n",
    "        \"hourly_timestamp\": hours,\n",
    "        \"Date of arrival\": row[\"Date of arrival\"],\n",
    "        \"Date of departure\": row[\"Date of departure\"],\n",
    "        \"ETA_x\": row[\"ETA_x\"],\n",
    "        \"ETD_x\": row[\"ETD_x\"],\n",
    "        \"boat\": row[\"boat\"],\n",
    "        \"passengers\": row[\"passengers\"],\n",
    "        \"quay\": row[\"quay\"],\n",
    "        \"agent\": row[\"agent\"],\n",
    "        \"weight\": row[\"weight\"],\n",
    "        \"lenght\": row[\"lenght\"],\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = []\n",
    "with open(\"data/05_shifts.csv\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.split(\",\\n\")\n",
    "        if line[0] != \",,,,,,,\":\n",
    "            line[0] = line[0].split(\",\")\n",
    "            whole.append(line[0])\n",
    "\n",
    "head = whole[0]\n",
    "data = whole[1:]\n",
    "\n",
    "reg_date = re.compile(r\"^\\d{1,2}\\/\\d{1,2}\\/\\d{4}$\")\n",
    "data_lode = []\n",
    "for line in data:\n",
    "    if reg_date.match(line[1]):\n",
    "        line[0] = \"*\"\n",
    "    if line[0] == \"\" or line[0] == \"*\":\n",
    "        data_lode.append(line)\n",
    "\n",
    "result = split_list_of_lists(data_lode)\n",
    "flattened_first = [item for sublist in result[0] for item in sublist]\n",
    "flattened_second = [item for sublist in result[1] for item in sublist]\n",
    "flattened_third = [item for sublist in result[2] for item in sublist]\n",
    "flattened_fourth = [item for sublist in result[3] for item in sublist]\n",
    "flattened_fifth = [item for sublist in result[4] for item in sublist]\n",
    "flattened_sixth = [item for sublist in result[5] for item in sublist]\n",
    "flattened_seventh = [item for sublist in result[6] for item in sublist]\n",
    "\n",
    "shifts = pd.DataFrame({\n",
    "    \"Date\": flattened_first,\n",
    "    \"Boat1\": flattened_second,\n",
    "    \"Time1\": flattened_third,\n",
    "    \"Boat2\": flattened_fourth,\n",
    "    \"Time2\": flattened_fifth,\n",
    "    \"Boat3\": flattened_sixth,\n",
    "    \"Time3\": flattened_seventh\n",
    "})\n",
    "\n",
    "shifts.replace(\"\", np.nan, inplace=True)\n",
    "columns_to_check = shifts.columns[2:6]\n",
    "shifts = shifts.dropna(subset=columns_to_check, how=\"all\")\n",
    "\n",
    "df1 = shifts[[\"Date\", \"Boat1\", \"Time1\"]].rename(\n",
    "    columns={\"Boat1\": \"Boat\", \"Time1\": \"Time\"})\n",
    "df2 = shifts[[\"Date\", \"Boat2\", \"Time2\"]].rename(\n",
    "    columns={\"Boat2\": \"Boat\", \"Time2\": \"Time\"})\n",
    "df3 = shifts[[\"Date\", \"Boat3\", \"Time3\"]].rename(\n",
    "    columns={\"Boat3\": \"Boat\", \"Time3\": \"Time\"})\n",
    "\n",
    "df_combined = pd.concat([df1, df2, df3])\n",
    "df_combined = df_combined.dropna(subset=[\"Boat\", \"Time\"])\n",
    "\n",
    "shifts = df_combined.sort_values(by=[\"Date\"]).reset_index(drop=True)\n",
    "# Getting rid of Jewel of the Seas part 2, so it does not later duplicate\n",
    "shifts = shifts.drop(index=[22], axis=0)\n",
    "\n",
    "replacements = {\n",
    "    \"Aidabella\": \"AIDAbella\",\n",
    "    \"Aidaluna\": \"AIDAluna\",\n",
    "    \"AidaMar\": \"AIDAmar\",\n",
    "    \"Aidasol\": \"AIDAsol\",\n",
    "    \"Preziosa\": \"MSC Preziosa\",\n",
    "    \"Sverdrup\": \"Otto Sverdrup\",\n",
    "    \"Sverdrup ?\": \"Otto Sverdrup\",\n",
    "    \"Hamburg ?\": \"Hamburg\",\n",
    "    \"Ocean Majesty?\": \"Ocean Majesty\",\n",
    "    \"Mein Schiff\": \"Mein Schiff 4\",\n",
    "    \"Island Princess?\": \"Island Princess\",\n",
    "    \"Nieuw Statendam?\": \"Nieuw Statendam\",\n",
    "    \"Borealis 61'\": \"Borealis\",\n",
    "    \"Europa (Skarsv?g)\": \"Europa\",\n",
    "    \"Pacific World (p1800)\": \"Pacific World\",\n",
    "    \"Queen Viktoria (2200)\": \"Queen Viktoria\",\n",
    "    \"Ambience p1000\": \"Ambience\",\n",
    "    \"MS Marina p600\": \"MS Marina\",\n",
    "    \"Riviera p1258\": \"Riviera\",\n",
    "    \"Preziosa \": \"MSC Preziosa\",\n",
    "    \"Preziosa\": \"MSC Preziosa\",\n",
    "    \"Ambition?\": \"Ambition\",\n",
    "    \"Greg Mortimer p160\": \"Greg Mortimer\",\n",
    "    \"Vasgo Da Gama\": \"Vasco Da Gama\",\n",
    "    \"Arcadia p2388\": \"Arcadia\",\n",
    "    \"Jewel of the seas\": \"Jewel of the Seas\",\n",
    "    \"Sevens Seas Navigator\": \"Seven Seas Navigator\",\n",
    "    \"Seabourn Oviation\": \"Seabourn Ovation\"\n",
    "}\n",
    "shifts[\"Boat\"] = shifts[\"Boat\"].str.strip(\" ?\")\n",
    "shifts[\"Boat\"] = shifts[\"Boat\"].replace(replacements)\n",
    "shifts[\"Time\"] = shifts[\"Time\"].replace({\"1400 - 2000 (Anker)\": \"1400 - 2000\"})\n",
    "\n",
    "shifts[[\"Month\", \"Day\", \"Year\"]] = shifts[\"Date\"].str.split(\"/\", expand=True)\n",
    "shifts[\"Month\"] = shifts[\"Month\"].str.rjust(2, \"0\")\n",
    "shifts[\"Day\"] = shifts[\"Day\"].str.rjust(2, \"0\")\n",
    "shifts[\"Date_new\"] = shifts[\"Year\"] + \"-\" + \\\n",
    "    shifts[\"Month\"] + \"-\" + shifts[\"Day\"]\n",
    "\n",
    "shifts = shifts.drop([\"Month\", \"Day\", \"Year\", \"Date\"], axis=\"columns\")\n",
    "\n",
    "shifts[\"Time\"] = shifts[\"Time\"].str.strip()\n",
    "shifts[[\"ETA\", \"ETD\"]] = shifts[\"Time\"].str.split(\"-\", expand=True)\n",
    "\n",
    "columns_to_clean = [\"ETA\", \"ETD\"]\n",
    "shifts = clean_time_columns(shifts, columns_to_clean)\n",
    "shifts[\"ETD\"] = shifts[\"ETD\"].replace({\"2400\": \"2359\"})\n",
    "\n",
    "# Filling in ETA for Bolette, which was sent to us via Whatsapp\n",
    "update = [(40, \"ETA\", \"0900\")]\n",
    "corrections_in_rows(shifts, update)\n",
    "\n",
    "columns_to_reformat = [\"ETA\", \"ETD\"]\n",
    "shifts = reformat_time_columns(shifts, columns_to_reformat)\n",
    "\n",
    "shifts.loc[shifts[\"ETA\"] == \":\", \"ETA\"] = \"\"\n",
    "shifts.loc[shifts[\"ETD\"] == \":\", \"ETD\"] = \"\"\n",
    "\n",
    "shifts = shifts.rename(\n",
    "    columns={\"Boat\": \"boat\", \"Time\": \"time\", \"Date_new\": \"date\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of Cruises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruises = pd.read_csv(\"data/01_cruises.csv\")\n",
    "cruises = cruises[[\"Dato\", \"ETA\", \"ETD\", \"Navn\",\n",
    "                   \"Passasjerer\", \"Kai\", \"Agent\", \"Tonn\", \"Lengde\"]]\n",
    "cruises = cruises.rename(columns={\"Dato\": \"date\", \"Navn\": \"boat\", \"Passasjerer\": \"passengers\",\n",
    "                         \"Kai\": \"quay\", \"Tonn\": \"weight\", \"Lengde\": \"lenght\", \"Agent\": \"agent\"})\n",
    "\n",
    "update = [\n",
    "    (16, \"ETA\", \"08:00\"),\n",
    "    (16, \"ETD\", \"17:00\"),\n",
    "    (47, \"ETD\", \"16:00\"),\n",
    "    (49, \"ETA\", \"14:00\"),\n",
    "    (113, \"ETD\", \"23:00\")\n",
    "]\n",
    "\n",
    "corrections_in_rows_soft(cruises, update)\n",
    "\n",
    "# Getting rid of all the boats that did not arrive\n",
    "cruises = cruises.drop(index=[15, 49, 115, 160], axis=0)\n",
    "\n",
    "cruises[\"boat\"] = cruises[\"boat\"].replace(replacements)\n",
    "\n",
    "cruises[[\"Day\", \"Month\", \"Year\"]] = cruises[\"date\"].str.split(\".\", expand=True)\n",
    "cruises[\"Date of arrival\"] = cruises[\"Year\"] + \\\n",
    "    \"-\" + cruises[\"Month\"] + \"-\" + cruises[\"Day\"]\n",
    "cruises[\"Date of departure\"] = cruises[\"Date of arrival\"]\n",
    "cruises = cruises.drop([\"date\", \"Day\", \"Month\", \"Year\"], axis=\"columns\")\n",
    "\n",
    "cruises = cruises[[\"Date of arrival\", \"Date of departure\", \"ETA\", \"ETD\", \"boat\", \"passengers\", \"quay\", \"agent\",\n",
    "                   \"weight\", \"lenght\"]]\n",
    "\n",
    "cruises[\"date\"] = cruises[\"Date of arrival\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining into Harbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.merge(cruises, shifts, on=[\"date\", \"boat\"], how=\"outer\")\n",
    "\n",
    "# Replace time in table cruises with time in table shifts if there is any\n",
    "combined[\"ETA_x\"] = combined[\"ETA_x\"].mask(\n",
    "    combined[\"ETA_y\"].notna() & (combined[\"ETA_y\"] != \"\"), combined[\"ETA_y\"])\n",
    "combined[\"ETD_x\"] = combined[\"ETD_x\"].mask(\n",
    "    combined[\"ETD_y\"].notna() & (combined[\"ETD_y\"] != \"\"), combined[\"ETD_y\"])\n",
    "\n",
    "# Loose all the columns no longer needed\n",
    "combined = combined.drop([\"date\", \"time\", \"ETA_y\", \"ETD_y\"], axis=\"columns\")\n",
    "\n",
    "combined[\"ETA date\"] = combined[\"Date of arrival\"] + \\\n",
    "    \" \" + combined[\"ETA_x\"] + \":00\"\n",
    "combined[\"ETD date\"] = combined[\"Date of arrival\"] + \\\n",
    "    \" \" + combined[\"ETD_x\"] + \":00\"\n",
    "\n",
    "# Change to datetime\n",
    "combined[\"ETA date\"] = pd.to_datetime(combined[\"ETA date\"], errors=\"coerce\")\n",
    "combined[\"ETD date\"] = pd.to_datetime(combined[\"ETD date\"], errors=\"coerce\")\n",
    "\n",
    "# Time difference between ETA and ETD: -1 day if the boat stayed over midnight\n",
    "combined[\"Time in harbour\"] = combined[\"ETD date\"] - combined[\"ETA date\"]\n",
    "\n",
    "combined[\"Date of arrival\"] = pd.to_datetime(combined[\"Date of arrival\"])\n",
    "combined[\"Date of departure\"] = pd.to_datetime(combined[\"Date of departure\"])\n",
    "\n",
    "day_added = combined[\"Time in harbour\"] < \"0 days 00:00:00\"\n",
    "combined.loc[day_added,\n",
    "             \"Date of departure\"] = combined[\"Date of departure\"] + timedelta(days=1)\n",
    "combined.loc[day_added, \"ETD date\"] = combined[\"ETD date\"] + timedelta(days=1)\n",
    "\n",
    "# Day added to the only exception in dataset - Jewel of the sea\n",
    "combined.loc[45, \"Date of departure\"] += timedelta(days=1)\n",
    "combined.loc[45, \"ETD date\"] += timedelta(days=1)\n",
    "\n",
    "# Create hour by hour situation in harbour\n",
    "combined = pd.concat([expand_rows(row)\n",
    "                     for index, row in combined.iterrows()], ignore_index=True)\n",
    "\n",
    "combined = combined.drop(\n",
    "    [\"Date of arrival\", \"Date of departure\", \"ETA_x\", \"ETD_x\"], axis=\"columns\")\n",
    "combined.to_csv(\"data/harbour_for_realsies.csv\", encoding=\"utf-8\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
